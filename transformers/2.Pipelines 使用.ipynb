{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d341815a-0461-4556-ae0c-7ad38c420d37",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "**Pipelines(管道)** 是使用模型进行推理的一种简单易上手的方式。\n",
    "\n",
    "这些管道是抽象了Transformers 库中大部分复杂代码的对象，提供了一个专门用于多种任务的简单API，包括**命名实体识别、掩码语言建模、情感分析、特征提取和问答**等等。\n",
    "\n",
    "\n",
    "\n",
    "| Modality                    | Task                         | Description                                                | Pipeline API                                  |\n",
    "| --------------------------- | ---------------------------- | ---------------------------------------------------------- | --------------------------------------------- |\n",
    "| Audio                       | Audio classification         | 为音频文件分配一个标签                                     | pipeline(task=“audio-classification”)         |\n",
    "|                             | Automatic speech recognition | 将音频文件中的语音提取为文本                               | pipeline(task=“automatic-speech-recognition”) |\n",
    "| Computer vision             | Image classification         | 为图像分配一个标签                                         | pipeline(task=“image-classification”)         |\n",
    "|                             | Object detection             | 预测图像中目标对象的边界框和类别                           | pipeline(task=“object-detection”)             |\n",
    "|                             | Image segmentation           | 为图像中每个独立的像素分配标签（支持语义、全景和实例分割） | pipeline(task=“image-segmentation”)           |\n",
    "| Natural language processing | Text classification          | 为给定的文本序列分配一个标签                               | pipeline(task=“sentiment-analysis”)           |\n",
    "|                             | Token classification         | 为序列里的每个 token 分配一个标签（人, 组织, 地址等等）    | pipeline(task=“ner”)                          |\n",
    "|                             | Question answering           | 通过给定的上下文和问题, 在文本中提取答案                   | pipeline(task=“question-answering”)           |\n",
    "|                             | Summarization                | 为文本序列或文档生成总结                                   | pipeline(task=“summarization”)                |\n",
    "|                             | Translation                  | 将文本从一种语言翻译为另一种语言                           | pipeline(task=“translation”)                  |\n",
    "| Multimodal                  | Document question answering  | 根据给定的文档和问题回答一个关于该文档的问题。             | pipeline(task=“document-question-answering”)  |\n",
    "|                             | Visual Question Answering    | 给定一个图像和一个问题，正确地回答有关图像的问题           | pipeline(task=“vqa”)                          |\n",
    "\n",
    "\n",
    "\n",
    "Pipelines 已支持的完整任务列表：[https://huggingface.co/docs/transformers/task_summary](https://huggingface.co/docs/transformers/task_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352eba10-3986-43de-9460-9802b237d21f",
   "metadata": {},
   "source": [
    "## Natural Language Processing(NLP)\n",
    "\n",
    "NLP(自然语言处理）任务是最常见的任务类型之一，因为文本是我们进行交流的一种自然方式。要将文本转换为模型可识别的格式，需要对其进行分词。这意味着将一系列文本划分为单独的单词或词组，然后将这些标记转换为数字。结果就是，你可以将一系列文本表示为一系列数字，并且一旦你拥有一系列数字，它就可以输入到模型中来解决各种NLP任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ba46b-b8b9-4808-a65b-94ffab3e1c17",
   "metadata": {},
   "source": [
    "## Pipeline API\n",
    "\n",
    "Pipeline API是对所有其他可用管道的包装。它可以像任何其他管道一样实例化，并且降低AI推理的学习和使用成本。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be02e0-44c9-4d3f-b5ca-f44910873aa2",
   "metadata": {},
   "source": [
    "### 使用Pipeline API实现 Text Classification\n",
    "\n",
    "Text Classification（文本分类）与任何模态中的分类任务一样，文本分类将一个文本序列（可以是句子级别、段落或者整篇文章）标记为预定义的类别集合之一。文本分类有许多实际应用，其中宝库哦：\n",
    "- 情感分析：根据某种极性（如积极或消极）对文本进行标记，以在政治、金融和市场等领域支持决策制定。\n",
    "- 内容分类：根据某个主题对文本进行标记，以帮助组织和过滤新闻和社交媒体信息流中的信息（天气、体育、金融等）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a25db-229e-4d6d-93d4-e2db305a7155",
   "metadata": {},
   "source": [
    "**下载模型**\n",
    "\n",
    "模型主页：[https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "\n",
    "- 在HuggingFace下载\n",
    "```bash\n",
    "git lfs install\n",
    "git clone https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "```\n",
    "\n",
    "- 在魔塔社区下载\n",
    "```bash\n",
    "git lfs install\n",
    "git clone https://oauth2:RmL-fB_xyUQstezmhXUf@www.modelscope.cn/hengzq/distilbert-base-uncased-finetuned-sst-2-english.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97047b4e-20fc-4657-97dc-ce8b8966aeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997431635856628}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 模型路径\n",
    "model_path = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model_path)\n",
    "pipe(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3254f75e-0723-431f-a20e-a3d36f2dfbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.6329299807548523},\n",
       " {'label': 'NEGATIVE', 'score': 0.7964168787002563}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 批处理调用模型推理\n",
    "\n",
    "text_list = [\n",
    "    \"今天西安天气很好\",\n",
    "    \"西红柿炒鸡蛋怎么做\"\n",
    "]\n",
    "\n",
    "pipe(text_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f58731-a9d1-4266-8f51-a854be231872",
   "metadata": {},
   "source": [
    "### 使用Pipeline API实现 Token Classification \n",
    "\n",
    "**Token Classification**(Token分类)将每个token分配一个来自预定义类别集的标签\n",
    "\n",
    "两种常见的Token分类：\n",
    "- 命名实体识别(NER):根据实体类别对token进行标记。NER在生物医学设置中特别受欢迎，可以标记基因、蛋白质和药物名称。\n",
    "- 词性标注(POS):根据其词性（如名词、动词或形容词）对标记进行标记。POS对于帮助翻译系统了解两个相同的单词如何在语法上不同很有用。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd84190-79e1-4424-9f41-dc242dc5f536",
   "metadata": {},
   "source": [
    "**下载模型**\n",
    "\n",
    "模型主页：[https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n",
    "\n",
    "- 在HuggingFace下载\n",
    "```bash\n",
    "git lfs install\n",
    "git clone https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english\n",
    "```\n",
    "\n",
    "- 在魔塔社区下载\n",
    "```bash\n",
    "git lfs install\n",
    "git clone https://oauth2:RmL-fB_xyUQstezmhXUf@www.modelscope.cn/hengzq/bert-large-cased-finetuned-conll03-english.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df55357-4287-4c88-82fe-48aaa34d5185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/hengzq/workspace/modelscope/models/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"/home/hengzq/workspace/modelscope/models/bert-large-cased-finetuned-conll03-english\"\n",
    "\n",
    "classifier = pipeline(task=\"ner\", model = model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9aad9a-3f7b-4e07-8309-47b8ff4be59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8aef2f-a030-4124-95dd-19f18721261a",
   "metadata": {},
   "source": [
    "### 使用Pipeline API实现 Question Answering\n",
    "\n",
    "**Question Answering**(问答)是另一个token-level的任务，返回一个问题的答案，有时带有上下文（开放领域），有时不带上下文（封闭领域）。每当我们向虚拟助手提问问题时，例如询问一家餐厅是否营业，就会发生这种情况。它还可以提供客户或技术支持，并帮助搜索引擎检索你要求的相关信息。\n",
    "\n",
    "有两种常见的问答类型：\n",
    "- 提取式：给定一个问题和一些上下文，模型必须从上下文中提取出一段文字作为答案。\n",
    "- 生成式：给定一个问题和一些上下文，答案是根据上下文生成的；这种方法由`Text2TextGenerationPipeline`处理，而不是下面展示的`QuestionAnsweringPipeline`\n",
    "\n",
    "\n",
    "\n",
    "**下载模型**\n",
    "\n",
    "模型主页：[https://www.modelscope.cn/models/Qwen/Qwen2.5-0.5B](https://www.modelscope.cn/models/Qwen/Qwen2.5-0.5B)\n",
    "\n",
    "- 在HuggingFace下载\n",
    "```bash\n",
    "git lfs install\n",
    "git clone https://huggingface.co/Qwen/Qwen2.5-0.5B\n",
    "```\n",
    "\n",
    "- 在魔塔社区下载\n",
    "```bash\n",
    "git lfs install\n",
    "git clone https://www.modelscope.cn/Qwen/Qwen2.5-0.5B.git\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e7acc-7035-4c9e-b2e9-8440a681bed4",
   "metadata": {},
   "source": [
    "## 使用 Pipeline 调用大语言模型\n",
    "\n",
    "语言建模是一项预测文本序列中的单词的任务。它已经成为非常流行的自然语言处理任务，因为预训练的语言模型可以用于许多其他下游任务的微调。最近，对大型语言模型（LLMs）产生了很大兴趣，这些模型展示了零或少量样本学习能力。这意味着该模型可以解决其未经明确训练过的任务！虽然语言模型可用于生成流畅且令人信服的文本，但需要小心使用，因为文本可能并不总是准确无误。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb287103-fb15-476d-8ddd-1707ac8ef655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '你能干什么呢？（） A. I can do it. B. I can do it. C. I can do it. D. I can do it. I can do it.\\n\\n以下是中国关于英语考试的主观题，请写出正确答案。\\n【题文】—What do you think of the film? —It’s ________ great! I can’t believe it. A．a B．an C．the D．/ 【答案】D\\n\\n以下是中国考试的主观题，请写出正确答案。\\n10. 2019 年 10 月 1 日，习近平总书记在庆祝中华人民共和国成立 70 周年大会上的讲话中指出， 70 年来，我们党团结带领人民在中国这片古老的土地上，书写了人类发展史上惊天地、泣鬼神的壮丽史诗，集中体现为完成和推进了三件大事。这三件大事是指（ ） ①完成了新民主主义革命 ②完成了社会主义革命 ③确立了中国特色社会主义制度 ④推进了全面深化改革 A. ①②③ B. ①②④ C. ①③④ D. ②③④ 10. 【答案】A 【解析】 本题考查新中国成立。 1949 年 10 月 1 日，中华人民共和国成立，标志着新民主主义革命的胜利，新民主主义革命的胜利，为实现由新民主主义向社会主义的过渡创造了前提条件，为实现中华民族伟大复兴创造了根本社会条件。 ①②③符合题意。 故选：A。 本题考查新中国成立。新中国成立，标志着新民主主义革命的胜利，新民主主义革命的胜利，为实现由新民主主义向社会主义的过渡创造了前提条件，为实现中华民族伟大复兴创造了根本社会条件。 本题考查学生对基础知识的识记能力，需要准确识记新中国成立的意义。\\n\\n以下是中国考试的主观题，请写出正确答案。\\n10. 2019 年 10 月 1 日，习近平总书记在庆祝中华人民共和国成立 70 周年大会上的讲话中指出， 70 年来，我们党团结带领人民在中国这片古老的土地上，书写了人类发展史上惊天地、泣鬼神的壮丽史诗，集中体现为完成和推进了三件大事。这三件大事是指（ ） ①完成了新民主主义革命 ②完成了社会主义革命 ③确立了中国特色社会主义制度 ④推进了全面深化改革 A. ①②③ B. ①②④ C. ①③④ D. ②③④ 【答案】A 【解析】 本题考查新中国成立。 1949 年 10 月 1 日，中华人民共和国成立，标志着新民主主义革命的胜利，新民主主义革命的胜利，为实现由新民主主义向社会主义的过渡创造了前提条件，为实现中华民族伟大复兴创造了根本社会条件。 ①②③符合题意。 故选：A。\\n\\n以下是中国考试的主观题，请写出正确答案。\\n【题文】下列关于细胞结构和功能的叙述，正确的是（ ） A．细胞膜上的受体是细胞间信息交流的通道 B．细胞核是细胞遗传和代谢的控制中心 C．细胞膜上的载体蛋白是细胞与外界环境进行物质交换的通道 D．细胞质基质是细胞代谢的主要场所 【答案】B\\n\\n以下是中国考试的主观题，请写出正确答案。\\n【题文】下列关于细胞结构和功能的叙述，正确的是（ ） A．细胞膜上的受体是细胞间信息交流的通道 B．细胞核是细胞遗传和代谢的控制中心 C．细胞膜上的载体蛋白是细胞与外界环境进行物质交换的通道 D．细胞质基质是细胞代谢的主要场所 【答案】D\\n\\n以下是中国考试的主观题，请写出正确答案。\\n【题文】下列关于细胞结构和功能的叙述，正确的是（ ） A．细胞膜上的受体是细胞间信息交流的通道 B．细胞核是细胞遗传和代谢的控制中心 C．细胞膜上的载体蛋白是细胞与外界环境进行物质交换的通道 D．细胞质基质是细胞代谢的主要场所 【答案】D\\n\\n以下是中国考试的主观题，请写出正确答案。\\n【题文】下列关于细胞结构和功能的叙述，正确的是（ ） A．细胞膜上的受体是细胞间信息交流的通道 B．细胞核是细胞遗传和代谢的控制中心 C．细胞膜上的载体蛋白是细胞与外界环境进行物质交换的通道 D．细胞质基质是细胞代谢的主要场所 【答案】D'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_path = \"/home/hengzq/workspace/large-model/Qwen2.5-0.5B\"\n",
    "\n",
    "prompt = \"你能干什么呢？\"\n",
    "generator = pipeline(task = \"text-generation\", model = model_path)\n",
    "\n",
    "generator(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14878ff3-5251-4521-bb41-c7d3e1862af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
